{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import logging\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from random import randint\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException, NoSuchAttributeException, ElementNotSelectableException, NoSuchDriverException"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping currencies information on 2023/08/25 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_coins_data():\n",
    "    driver = webdriver.Firefox()\n",
    "    try:\n",
    "        driver.get(\"https://coinmarketcap.com/historical/20230825/\")\n",
    "    except NoSuchDriverException as err:\n",
    "        print(\"Error occurred: {}\".format(err))\n",
    "    time.sleep(1)\n",
    "    scroll_page(driver)\n",
    "    coins = get_coin_data(driver)\n",
    "    driver.quit()\n",
    "    with open(\"currency_data.json\", \"w\") as file:\n",
    "        json.dump(coins, file)\n",
    "    df = pd.read_json(\"currency_data.json\")\n",
    "    df.to_csv((\"currency_data.csv\", index=False))\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrolling Main Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_page(driver):\n",
    "    pos = 500\n",
    "    for _ in range(0, 20):\n",
    "        driver.execute_script(\"window.scrollTo(0, \" + str(pos) + \")\")\n",
    "        pos += 500\n",
    "        time.sleep(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Currencies data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coin_data(driver):\n",
    "    rows = driver.find_elements(By.CSS_SELECTOR, \".cmc-table-row\")\n",
    "    currencies = []\n",
    "    for row in rows:\n",
    "        try:\n",
    "            currency = {}\n",
    "            currency[\"rank\"] = row.find_element(By.CSS_SELECTOR, \".cmc-table__cell--sort-by__rank div\").text\n",
    "            element = row.find_element(By.CSS_SELECTOR, \".cmc-table__column-name--name\")\n",
    "            currency[\"name\"] = element.get_attribute(\"title\")\n",
    "            currency[\"symbol\"] = row.find_element(By.CSS_SELECTOR, \".cmc-table__column-name--symbol\").get_attribute(\"textContent\")\n",
    "            currency[\"circulating_supply\"] = int(\"\".join(filter(str.isdigit, row.find_element(By.CSS_SELECTOR, \".cmc-table__cell--sort-by__circulating-supply div\").text)))\n",
    "            currency[\"main_link\"] = element.get_attribute(\"href\")\n",
    "            currency[\"historical_link\"] = coin[\"main_link\"] + \"historical-data/\"\n",
    "            currencies.append(currency)\n",
    "        except (NoSuchElementException, NoSuchAttributeException, ElementNotSelectableException) as err:\n",
    "            print(\"Error occurred: {}\".format(err))\n",
    "    return currencies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Currencies Extra Information From Main Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_coins_extras(df):\n",
    "    git = webdriver.Firefox()\n",
    "    extras_list = []\n",
    "    coins = df.to_dict(\"records\")\n",
    "    for ex in coins:\n",
    "        extras = get_coin_extras(git, ex[\"main_link\"])\n",
    "        extras_list.append(extras)\n",
    "    git.quit()\n",
    "    df_extra = pd.DataFrame(extras_list)\n",
    "    df_extra['currency_id'] = [ex['rank'] for ex in coins]\n",
    "    new_cols = [\"currency_id\", \"github_link\", \"tags\"]\n",
    "    df_extra = df_extra[new_cols]\n",
    "    return df_extra\n",
    "\n",
    "df_main = scrape_coins_data()\n",
    "df_extra = scrape_coins_extras(df_main)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Currencies Extra data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coin_extras(driver, currency_url):\n",
    "    try:\n",
    "        driver.get(currency_url)\n",
    "        try:\n",
    "            github_link_element = driver.find_element(By.XPATH, \"//a[contains(@href, 'github.com')]\")\n",
    "            github_link = github_link_element.get_attribute('href')\n",
    "        except NoSuchElementException:\n",
    "            github_link = \"\"\n",
    "        try:\n",
    "            driver.find_element(By.CSS_SELECTOR, \".sc-b7faf77f-1.kpTZfr\").click()\n",
    "            tags_elements = driver.find_elements(By.CSS_SELECTOR, \".cmc-modal .ctYAzo .cmc-link\")\n",
    "            tags = [tag_element.text for tag_element in tags_elements]\n",
    "        except NoSuchElementException:\n",
    "            tags_elements = driver.find_elements(By.CSS_SELECTOR, \".jaPKUl .ctYAzo .cmc-link\")\n",
    "            tags = [tag_element.text for tag_element in tags_elements]\n",
    "            while '' in tags:\n",
    "                tags.remove('')\n",
    "    except NoSuchElementException:\n",
    "        raise Exception(\"Failed to find elements\")\n",
    "    return {\"github_link\": github_link, \"tags\": tags}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scarping Github Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_url(url):  # Function to check currency link\n",
    "    if url == \"?\":  # When the currency doesn't have github link\n",
    "        return -1\n",
    "    if (url.count(\"/\") == 4) & (\n",
    "        url[-1] != \"/\"):  # When the currency has github repository link\n",
    "        return 1\n",
    "    if (url.count(\"/\") == 3) | (\n",
    "        (url.count(\"/\") == 4) & (url[-1] == \"/\")):  # When the currency has github project link\n",
    "        return\n",
    "    return 0  # When the currency has an other link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(url): # function to send request and return parsed page\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        return soup\n",
    "    except HTTPError as http_err:\n",
    "        print(\"HTTP error occurred: {}\".format(http_err))\n",
    "    except ConnectionError as conn_err:\n",
    "        print(\"Connection error occurred: {}\".format(conn_err))\n",
    "    except Timeout as timeout_err:\n",
    "        print(\"Timeout error occurred: {}\".format(timeout_err))\n",
    "    except RequestException as req_err:\n",
    "        print(\"Request error occurred: {}\".format(req_err))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_repo(url, id):  # function to scrape repository links and return data\n",
    "    try:\n",
    "        page = get_page(url)\n",
    "        boxs = page.select(\".text-small.mr-3\")\n",
    "        languages = []\n",
    "        for box in boxs:\n",
    "            language = {}\n",
    "            elements = box.select(\"span\")\n",
    "            language[\"coin_id\"] = id\n",
    "            language[\"name\"] = elements[0].text\n",
    "            language[\"percentage\"] = float(elements[1].text[:-1])\n",
    "            languages.append(language)\n",
    "        data = {}\n",
    "        data[\"coin_id\"] = id\n",
    "        commit_element = page.select(\".ml-md-3 strong\")\n",
    "        data[\"commits_count\"] = int(\n",
    "            \"\".join(filter(str.isdigit, commit_element[0].text))\n",
    "        )\n",
    "        contrib_element = page.select(\".Link.flex-items-center\")\n",
    "        for element in contrib_element:\n",
    "            if \"Contributors\" in element.text:\n",
    "                data[\"contributors_count\"] = int(\n",
    "                    \"\".join(filter(str.isdigit, element.text))\n",
    "                )\n",
    "        fork_count = page.find(id=\"repo-network-counter\").get(\"title\")\n",
    "        data[\"forks_count\"] = int(\"\".join(filter(str.isdigit, fork_count)))\n",
    "        star_count = page.find(id=\"repo-stars-counter-star\").get(\"title\")\n",
    "        data[\"stars_count\"] = int(\"\".join(filter(str.isdigit, star_count)))\n",
    "        return [languages, data]\n",
    "    except:\n",
    "        print(\"error in scraping {}th coin.\".format(id))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(url, id):  # Ù‘ Function that calls the appropriate function for each currency\n",
    "    case = check_url(url)\n",
    "    if case == -1:  # When the currency doesn't have github link\n",
    "        return None\n",
    "    if case == 1:  # When the currency has github repository link\n",
    "        return scrape_repo(url, id)\n",
    "    if (\n",
    "        case == 0\n",
    "    ):  # When the currency has another link and its project link should be separated\n",
    "        parts = url.split(\"/\")\n",
    "        url = \"/\".join(parts[:4])\n",
    "    return scrape_prjct(url, id)  # When the currency has github project link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrape projects links(finding repository link of currency and scrape it)\n",
    "def scrape_prjct(url, id):\n",
    "    try:\n",
    "        page = get_page(url)\n",
    "        repo_url = \"https://github.com\" + page.select(\".col-lg-6:nth-child(1) a\")[\n",
    "            0\n",
    "        ].get(\"href\")\n",
    "        return scrape_repo(repo_url, id)\n",
    "    except:\n",
    "        print(\"error in finding {}th coin link.\".format(id))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data and fix some links\n",
    "currency_data = df_extra\n",
    "currency_data[\"github_link\"].replace(pd.NA, \"?\", inplace=True)\n",
    "value_mapping = {\n",
    "    \"https://github.com/solana-labs\": \"https://github.com/solana-labs/solana\",\n",
    "    \"https://github.com/maticnetwork/whitepaper/\": \"https://github.com/maticnetwork/bor\",\n",
    "    \"https://github.com/filecoin-project/\": \"https://github.com/filecoin-project/lotus\",\n",
    "    \"https://github.com/quantnetwork/\": \"?\",\n",
    "    \"https://github.com/chainsulting/Smart-Contract-Security-Audits/tree/master/ApeCoin\": \"?\",\n",
    "    \"https://github.com/thorchain/Resources/tree/master/Whitepapers/THORChain/whitepaper-en.md\": \"https://github.com/thorchain/THORChain-v1\",\n",
    "    \"https://github.com/iotaledger\": \"https://github.com/iotaledger/wasp\",\n",
    "    \"https://github.com/curvefi/curve-contract\": \"https://github.com/curvefi/curve-stablecoin\",\n",
    "    \"https://github.com/gatechain\": \"https://github.com/gatechain/crypto\",\n",
    "    \"https://github.com/trustwallet\": \"https://github.com/trustwallet/wallet-core\",\n",
    "    \"https://github.com/dydxfoundation/\": \"?\",\n",
    "    \"https://github.com/BTCGPU/BTCGPU/wiki/Technical-Spec\": \"https://github.com/BTCGPU/BTCGPU\",\n",
    "    \"https://github.com/singnet/\": \"https://github.com/singnet/snet-daemon\",\n",
    "    \"https://github.com/balancer-labs\": \"?\",\n",
    "    \"https://github.com/kusamanetwork\": \"?\",\n",
    "    \"https://github.com/worldcoin\": \"?\",\n",
    "    \"https://github.com/Solar-network\": \"https://github.com/Solar-network/core\",\n",
    "    \"https://github.com/axelarnetwork\": \"https://github.com/axelarnetwork/axelar-core\",\n",
    "    \"https://github.com/terra-project\": \"https://github.com/terra-money/core\",\n",
    "    \"https://github.com/nervosnetwork/rfcs/blob/master/rfcs/0002-ckb/0002-ckb.md\": \"https://github.com/nervosnetwork/ckb\",\n",
    "    \"https://github.com/UMAprotocol/whitepaper\": \"?\",\n",
    "    \"https://github.com/reserve-protocol\": \"https://github.com/reserve-protocol/rsv-v2\",\n",
    "    \"https://github.com/kybernetwork\": \"?\",\n",
    "}\n",
    "currency_data[\"github_link\"] = currency_data[\"github_link\"].replace(value_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_data = []\n",
    "github_data = []\n",
    "for i in tqdm(range(0, 200)):  # Iterating over all currencies and scrape data of them\n",
    "    extra_data = scrape(currency_data[\"github_link\"][i], currency_data[\"currency_id\"][i])\n",
    "    if extra_data != None:\n",
    "        languages_data.extend(extra_data[0])\n",
    "        github_data.append(extra_data[1])\n",
    "    if (i + 1) % 10 == 0:\n",
    "        time.sleep(10)\n",
    "\n",
    "lang_coin_df = pd.DataFrame(languages_data)\n",
    "git_df = pd.DataFrame(github_data)\n",
    "\n",
    "languages_df = pd.DataFrame({'name': lang_coin_df['name'].unique()})\n",
    "languages_df['id'] = range(1, len(languages_df) + 1)\n",
    "lang_coin_df['language_id'] = lang_coin_df['name'].map(languages_df.set_index('name')['id'])\n",
    "lang_coin_df = lang_coin_df[['coin_id', 'language_id', 'percentage']]\n",
    "languages_df = languages_df[['id', 'name']]\n",
    "\n",
    "lang_coin_df.to_csv(\"currency_lang_data.csv\", index=False)\n",
    "languages_df.to_csv(\"languages.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_extra = df_extra\n",
    "new_df_extra['tags'] = new_df_extra['tags'].apply(ast.literal_eval)\n",
    "distinct_tags = pd.unique([tag for sublist in new_df_extra['tags'] for tag in sublist])\n",
    "tags_df = pd.DataFrame({'id': range(1, len(distinct_tags) + 1),\n",
    "                    'name': list(distinct_tags)})\n",
    "\n",
    "corrency_tag_df = pd.DataFrame([(row.rank, tag_id)\n",
    "                    for row in new_df_extra.itertuples(index=False)\n",
    "                    for tag_id, tag in tags_df.itertuples(index=False)\n",
    "                    if tag in row.tags],\n",
    "                   columns=['corrency_id', 'tag_id'])\n",
    "\n",
    "new_df_extra.drop('tags', axis=1, inplace=True)\n",
    "corrency_tag_df.to_csv('currency_tag_data.csv', index=False)\n",
    "tags_df.to_csv('tags.csv', index=False)\n",
    "\n",
    "github_df = git_df\n",
    "merged_df = pd.merge(new_df_extra, github_df, on='currency_id', how='inner')\n",
    "\n",
    "github_df['github_link'] = merged_df['github_link']\n",
    "github_df.to_csv('complete_github_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_driver(url, logger):\n",
    "    try:\n",
    "        # Make download_directory\n",
    "        folder_name = \"Scraped_data\"\n",
    "        current_directory = os.getcwd()\n",
    "        parent_directory = os.path.dirname(current_directory)\n",
    "        download_directory = os.path.join(parent_directory, folder_name)\n",
    "        if not os.path.exists(download_directory):\n",
    "            os.mkdir(download_directory)\n",
    "\n",
    "        # Set download_directory to options\n",
    "        chrome_options = webdriver.ChromeOptions()\n",
    "        chrome_options.add_experimental_option(\"prefs\", {\n",
    "            \"download.default_directory\": download_directory,\n",
    "            \"download.prompt_for_download\": False,\n",
    "            \"download.directory_upgrade\": True,\n",
    "            \"safebrowsing.enabled\": True\n",
    "        })\n",
    "\n",
    "        # Create driver\n",
    "        driver = webdriver.Chrome(options=chrome_options)\n",
    "        driver.get(url)\n",
    "        return driver\n",
    "    except NoSuchDriverException as err:\n",
    "        logger.error(\"No Such Driver occurred: {}\".format(err))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Histortical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(driver, url):\n",
    "    try:\n",
    "        # Find and click on date button\n",
    "        date_button = driver.find_elements(By.CSS_SELECTOR, '.htGqtu button.dalfmx')[0]\n",
    "        date_button.click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        # Find and click on 'Last 365 days' button\n",
    "        li_element = driver.find_element(By.CSS_SELECTOR, '.heoICr li:last-child')\n",
    "        driver.execute_script(\"arguments[0].click();\", li_element)\n",
    "        time.sleep(1)\n",
    "\n",
    "        # Find and click on 'Continue' button\n",
    "        continue_button = driver.find_element(By.CSS_SELECTOR, '.bcCCXI')\n",
    "        driver.execute_script(\"arguments[0].click();\", continue_button)\n",
    "        time.sleep(5)\n",
    "\n",
    "        # Find and click on 'Download CSV' button\n",
    "        download_csv_button = driver.find_elements(By.CSS_SELECTOR, '.htGqtu button.dalfmx')[1]\n",
    "        download_csv_button.click()\n",
    "        time.sleep(3)\n",
    "\n",
    "    except NoSuchElementException as err:\n",
    "        logger.error(\"No Such Element occurred: {}\".format(err))\n",
    "    except ElementClickInterceptedException as err:\n",
    "        logger.error(\"Element Click Intercepted occurred: {}\".format(err))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Set up logging configuration\n",
    "    logging.basicConfig(filename='get_coins_csv_files.log', filemode='w', format='%(asctime)s %(levelname)s: %(message)s')\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    # Read urls\n",
    "    df = pd.read_csv('../Scraped_data/coins_data.csv')\n",
    "    urls = df['historical_link'].tolist()\n",
    "    # urls = urls[0:10]\n",
    "\n",
    "    for url_num in tqdm(range(len(urls))):\n",
    "        url = urls[url_num]\n",
    "        driver = get_driver(url, logger)\n",
    "\n",
    "        if driver != None:\n",
    "            try:\n",
    "                extract_data(driver, url)\n",
    "            except:\n",
    "                logger.warning('Failed to extract data from the page [{}]'.format(url))\n",
    "\n",
    "        # Sleep for a random time to avoid being blocked\n",
    "        time_milliseconds = randint(500, 2000)\n",
    "        time_sec = 0.001 * time_milliseconds\n",
    "        logger.info('Sleeping for {} seconds'.format(time_sec))\n",
    "        time.sleep(time_sec)\n",
    "        logger.info('Woke up')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
